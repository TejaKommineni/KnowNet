%%% -*-LaTeX-*-

\chapter{Conclusion} \label{chap:conclusion}

Section ~\ref{contributions} remarked the following thesis statement:

''By combining clustering and other data mining techniques we can produce a view of host behaviors that helps network administrators to understand behavior of the networks. This system complements existing network analysis tools to ease network management.''

We have found conclusive evidence for this statement by evaluating the university network data and the labeled data obtained from Center for Applied Internet Data Analysis (CAIDA). We analyzed hosts and studied the behavior of groups of hosts. This research of grouping hosts based on their behaviors is one of a kind and was conducive in comprehending the behvaior of networks. This system with the help of exisiting tools helped us in making recommendations to the network administrators about different management activities.
While evaluating the university network data, we found hosts exhibiting seven unique behaviors. We had hosts behaving as clients, servers, exchanging normal traffic and scanners. Few of these behaviors extracted by our system were inline with the expected behaviors by the network admins and others helped them better understand about the network.   

We also presented a web based assisting tool that helps in visualizing these behaviors over time periods and look into historic behaviors that this network exhibited.

While evaluating the various RDMA primitives, we found that one-sided RDMA verbs, though they offload destination CPU, 
require additional acknowledgment mechanisms. We also found that client-initiateds cannot use the scatter gather DMA engine effectively. We arrived at the conclusion that primitives 
are the most suited for returning scattered set of records.

We analyzed the transmission throughput of Zero Copy and Copy Out for 128~B records and found that bigger records can saturate the NIC.Zero Copy is significantly faster for bigger chunks. Zero Copy is also limited by the length of S/G list for small 128~B records.
We also found that Copy Out can perform better if you have more records. We arrived at the following conclusion that 
unless your records are small and scattered, always use Zero Copy; for small and scattered records, you might need to tune your layout to get Zero Copy advantage.

Zero Copy with two-sided RDMA promises CPU savings by offloading CPU from the critical data transfer path of the sender. We found that CPU overheads in transmissions are largely due to the additional copies involved in Copy Out and Zero Copy benefits from avoiding the extra copy.

CPU efficiency of transmission is better measured in cycles spent per transmitted byte. We see that even transmitting two records at a time makes Zero Copy more CPU efficient in transmission and the gains get bigger for bigger transmissions.

Memory bandwidth is a crucial resource in an in-memory database server bound by DRAM capacity and latency. We found that for transfer of large records, the pressure on the memory controller is approximately 2X the transmission throughput and while transmitting at the line rate of our NIC, the server consumed half of all available memory bandwidth. If memory bandwidth is not an expendable resource, we ascertain that the designer should 
always use Zero Copy.

Intel\textregistered's recent micro-architectures have support for DDIO that treats LLC as the source and destination for I/O transfers. This has a significant impact on 
the memory pressure exerted to the system, especially for Copy Out. DDIO paints a slightly different picture favoring Copy Out since the cost of prefetching the data is 
paid up front; we do not incur additional misses from DDIO. This is less relevant in the bigger scheme of things and Zero Copy still wins in terms of total 
consumed memory bandwidth in the server

The transmission throughput anomaly where the throughput of Zero Copy is limited while transferring a large set of small scattered records is best explained to 
our knowledge with PCIe errors tapering off with 16 records per transmission.

We argued for a client-assisted design with no-update-in-place records that can gain the benefits of Zero Copy while retaining the transmission throughput of larger records. 
We get a 50\% reduction in memory bandwidth consumption using this approach without compromising transmission throughput. 
Having no updates in place and latch and lock freedom make this approach clearly favorable for the modern NIC. 

We also laid out the basic design for a new migration protocol in RAMCloud that makes use of Zero Copy, smart layout for transmission and bypassing re-replication using 
RDMA.

\section{Future Directions}

\begin{enumerate}
	\item Investigate and build applications using the results of our system. Our system groups hosts exhibiting similar behaviors and defines each group by certain characteristics such as the cluster sizes, cluster centers etc.. Using this information about each group we can build various applications such as anamoly detectors, dynamic firewall rule generators or bandwidth predictors which can become further handy to network administrators in their day-to-day activiites.
	
	\item In our work we define host as any unique IP address that has in-bound or out-bound traffic. But, network users needn't always have a unique IP address. Each user can be communicating in a network with multiple IP addresses. This could happen because of a malicious user trying to hide his identitity by using different IP addresses or because of dynamic allotment by ISP provider. In that direction it would be useful to group hosts at a user level instead of using IP address as a basis. Even in this approach most of our techniques should work well. 
	
	\item When analyzed with labeled data our sytsem had higher accuracy in scenario1 and scenario3 but when it comes to detecting chinese hosts or multi network scenarios our rate of detection is a bit low. We could further improve the accuracy by tuning our system. Few pointers to explore here are to evaluate different normalizing techniques.
	
	\item Build an actual migration protocol for RAMCloud. changing behaviors and streaming algos.	 concurrent programming to speed up.
\end{enumerate}

\section{Lessons Learned}
We started out to measure the impact of data layout and pre-aggregation on network transmit performance. 
It was rewarding to explore the complexities of handling kernel by-pass over the InfiniBand library and 
scoreboarding in a multithreaded environment to arrive at the right measurements for transmission.
It was also challenging to profile the code for additional metrics reflecting system resource consumption 
without disrupting the actual transmissions. 

I learned a lot while developing many portions of this system. My most important takeaway from this work is to handle huge amount of data, analyze and present the results of different data mining techniques in an understandable format to the user. Conducting of experiments with varying set ups is one part of the research where as digging deep into the results of these experiments to understand if they represent any innate structure of network behavior is another pivotal step in the research. 
I got first-hand experience in using various data science packages,  concurrent programming, use of InfiniBand verbs, RDMA, and accurate cycle counting 
for profiling wall time. I have significantly improved my scripting and documentation skills over the course of this work. 
I have also learned valuable lessons on teamwork and collaboration and received a lot of help from my advisor and peers over the course of the work. I believe the guidelines that we drew from this work will help researchers of the future develop better performing in-memory databases for large transfers. 

\section{Parting Thoughts}
Today's database designer has to navigate a complex, multidimensional space of trade-offs and network transmission 
is a critical aspect of performance for the distributed, scale out stores of tomorrow. Smart layout of data and  
co-designing for hardware are paramount in extracting maximum network performance without consuming 
unnecessary system resources. The use of Zero Copy offers better transmission throughput and memory bandwidth utilization for 
large transfers if we carefully co-design the software keeping the network hardware in mind. Research on how to extract 
more transmission performance from column-oriented layouts and advanced indexing structures should continue until we bridge the 
gap between what a modern distributed database server can deliver and what the hardware, especially fast networks, is capable of doing.